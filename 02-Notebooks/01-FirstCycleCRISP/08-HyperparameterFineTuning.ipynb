{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn           as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats as ss\n",
    "\n",
    "from IPython.display      import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# data balancing\n",
    "from imblearn.combine        import SMOTETomek\n",
    "# feature selection\n",
    "from boruta                  import BorutaPy\n",
    "from skopt                   import forest_minimize\n",
    "from xgboost                 import XGBClassifier\n",
    "from lightgbm                import LGBMClassifier\n",
    "from sklearn.metrics         import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.preprocessing   import RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawTrain = pd.read_feather('00-Data/FeatherData/trainDatasetScaling.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jupyter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use('bmh')\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML('<style>.container { width:100% !important; }</style>'))\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option('display.expand_frame_repr', False)\n",
    "    \n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlScores(modelName, y, yhat, yhatProba):\n",
    "    precision = precision_score(y, yhat)\n",
    "    recall = recall_score(y, yhat)\n",
    "    f1 = f1_score(y, yhat)\n",
    "    kappa = cohen_kappa_score(y, yhat)\n",
    "    ap = average_precision_score(y, yhatProba)\n",
    "    rocauc = roc_auc_score(y, yhatProba)\n",
    "    \n",
    "    return pd.DataFrame({ 'Model Name': modelName, \n",
    "                           'Precision': precision, \n",
    "                           'Recall': recall,\n",
    "                           'F1 Score': f1,\n",
    "                           'Kappa': kappa,\n",
    "                           'Average Precision Score': ap,\n",
    "                           'ROC AUC': rocauc}, index=[0])\n",
    "\n",
    "\n",
    "\n",
    "def crossValidation(XTraining, kfold, modelName, model, verbose=False):\n",
    "    precisionList = []\n",
    "    recallList = []\n",
    "    f1List = []\n",
    "    kappaList = []\n",
    "    apList = []\n",
    "    rocaucList = []\n",
    "    XTraining = XTraining.sample(frac=1).reset_index(drop=True)\n",
    "    for k in reversed(range(1, kfold+1)):\n",
    "        if verbose:\n",
    "            print(f'\\nKFold Number: {k}')\n",
    "        # Filtering Dataset\n",
    "        training = XTraining.iloc[0: k*(round(XTraining.shape[0]/(kfold+1))), :]\n",
    "        validation = XTraining.iloc[k*(round(XTraining.shape[0]/(kfold+1))) : (k+1)*(round(XTraining.shape[0]/(kfold+1))), :]\n",
    "\n",
    "        # Training and Validation Dataset\n",
    "        # Training\n",
    "        XKFoldTraining = training.drop(['Exited'], axis=1)\n",
    "        yKFoldTraining = training['Exited']\n",
    "\n",
    "        # Validation\n",
    "        XKFoldValidation = validation.drop(['Exited'], axis=1)\n",
    "        yKFoldValidation = validation['Exited']\n",
    "        \n",
    "        # set the resampler\n",
    "#         resampler = SMOTETomek(random_state=42, n_jobs=-1)\n",
    "#         # resample the dataset\n",
    "#         XKFoldTrainingBalanced, yKFoldTrainingBalanced = resampler.fit_resample(XKFoldTraining, yKFoldTraining)\n",
    "#         XKFoldValidationBalanced = XKFoldValidation\n",
    "#         yKFoldValidationBalanced = yKFoldValidation\n",
    "        #XKFoldValidationBalanced, yKFoldValidationBalanced = resampler.fit_resample(XKFoldValidation, yKFoldValidation)\n",
    "        \n",
    "        #Model\n",
    "        model.fit(XKFoldTraining, yKFoldTraining)\n",
    "\n",
    "        # Prediction\n",
    "        yhat = model.predict(XKFoldValidation)\n",
    "        \n",
    "        # Prediction Proba\n",
    "        yhatProba = model.predict_proba(XKFoldValidation)[:,1]\n",
    "\n",
    "        #Performance\n",
    "        modelResult = mlScores(modelName, yKFoldValidation, yhat, yhatProba)\n",
    "        \n",
    "        #Store Performance of each KFold iteration\n",
    "        precisionList.append(modelResult['Precision'].tolist())\n",
    "        recallList.append(modelResult['Recall'].tolist())\n",
    "        f1List.append(modelResult['F1 Score'].tolist())\n",
    "        kappaList.append(modelResult['Kappa'].tolist())\n",
    "        apList.append(modelResult['Average Precision Score'].tolist())\n",
    "        rocaucList.append(modelResult['ROC AUC'].tolist())\n",
    "    \n",
    "\n",
    "    dictResult = {\n",
    "                    'Model Name': [modelName],\n",
    "                    'Precision CV': [np.round(np.mean(precisionList),2).astype(str) + ' +/- ' + np.round(np.std(precisionList),2).astype(str)],\n",
    "                    'Recall CV': [np.round(np.mean(recallList),2).astype(str) + ' +/- ' + np.round(np.std(recallList),2).astype(str)],\n",
    "                    'F1 Score CV': [np.round(np.mean(f1List),2).astype(str) + ' +/- ' + np.round(np.std(f1List),2).astype(str)],\n",
    "                    'Kappa CV': [np.round(np.mean(kappaList),2).astype(str) + ' +/- ' + np.round(np.std(kappaList),2).astype(str)],\n",
    "                    'Average Precision Score CV': [np.round(np.mean(apList),2).astype(str) + ' +/- ' + np.round(np.std(apList),2).astype(str)],\n",
    "                    'ROC AUC CV': [np.round(np.mean(rocaucList),2).astype(str) + ' +/- ' + np.round(np.std(rocaucList),2).astype(str)]\n",
    "                }\n",
    "\n",
    "    return pd.DataFrame(dictResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df07 = dfRawTrain.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsSelectedBoruta = ['Age', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'AgeGroup_Midlife']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X,y Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "yTrain = df07['Exited']\n",
    "XTrain = df07[colsSelectedBoruta]\n",
    "\n",
    "# set the resampler\n",
    "resampler = SMOTETomek(random_state=42, n_jobs=-1)\n",
    "# resample the dataset\n",
    "XBalanced, yBalanced = resampler.fit_resample(XTrain, yTrain)\n",
    "\n",
    "dfTrain = pd.concat([XBalanced, yBalanced], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'After SMOTE')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plots before and after SMOTE\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x=yTrain);\n",
    "plt.title(\"Before SMOTE\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x=yBalanced);\n",
    "plt.title(\"After SMOTE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS\n",
    "---\n",
    "- Lightgbm Classifier\n",
    "- Random Forest Classifier\n",
    "- XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResultsLGBM = pd.DataFrame()\n",
    "dfResultsRF = pd.DataFrame()\n",
    "dfResultsXGB = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.009944912110647982, 5, 1, 0.4677107511929402, 0.49263223036174764, 272]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 7.7029\n",
      "Function value obtained: -0.8938\n",
      "Current minimum: -0.8938\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.0010385556240017917, 2, 10, 0.14183771058242609, 0.7437489153990157, 600]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 6.1302\n",
      "Function value obtained: -0.8112\n",
      "Current minimum: -0.8938\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.01250618338439657, 5, 6, 0.1541824778996655, 0.8682075103820793, 273]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 6.5153\n",
      "Function value obtained: -0.8924\n",
      "Current minimum: -0.8938\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.016490254525097375, 9, 9, 0.6502182010234373, 0.6866210554187129, 1069]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 104.4270\n",
      "Function value obtained: -0.9458\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.01834425482425403, 10, 1, 0.2804405187742579, 0.3448850990367951, 1182]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 256.4526\n",
      "Function value obtained: -0.9245\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.0014836076428283468, 1, 13, 0.8899029303129179, 0.9602665861392746, 214]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 2.6044\n",
      "Function value obtained: -0.6960\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.02614950849523158, 5, 8, 0.5439512623421213, 0.7483811103274842, 1057]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 26.3284\n",
      "Function value obtained: -0.9388\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.005883946521405699, 1, 7, 0.811247998237159, 0.6963955932783014, 1012]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 8.1523\n",
      "Function value obtained: -0.8391\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.009780455975240894, 3, 12, 0.44234694306528044, 0.399351303640462, 272]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 3.9955\n",
      "Function value obtained: -0.8697\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.0016477897665487307, 6, 18, 0.5235636153223084, 0.6728679300083596, 747]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 24.5948\n",
      "Function value obtained: -0.8873\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[0.00254165132488824, 6, 11, 0.6690058210062765, 0.11162953998372366, 549]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 13.3075\n",
      "Function value obtained: -0.8977\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[0.0010815024957285871, 7, 13, 0.44818888750823754, 0.07698719284334227, 1162]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 34.2704\n",
      "Function value obtained: -0.9029\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[0.01028491314690704, 5, 19, 0.43911554828921634, 0.6830058868416728, 763]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 17.0944\n",
      "Function value obtained: -0.9139\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[0.041299973169667735, 6, 9, 0.7785492724370529, 0.2041135068393704, 1197]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 28.2701\n",
      "Function value obtained: -0.9355\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[0.028323043345821718, 3, 6, 0.21682527769194165, 0.39592145550448316, 1158]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 13.7792\n",
      "Function value obtained: -0.9064\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[0.07153671917186938, 7, 16, 0.6175963856341403, 0.75095123468101, 303]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 10.8736\n",
      "Function value obtained: -0.9386\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[0.017293945600511968, 2, 15, 0.9007557574888567, 0.41026441194439994, 316]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 3.9681\n",
      "Function value obtained: -0.8606\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[0.005545743892663144, 6, 15, 0.222967175068081, 0.4403061604019928, 702]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 16.8781\n",
      "Function value obtained: -0.8943\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[0.07698616486747904, 6, 5, 0.5203391823730488, 0.2717918603763245, 887]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 20.9590\n",
      "Function value obtained: -0.9371\n",
      "Current minimum: -0.9458\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[0.018353598126553926, 4, 3, 0.47305622526323254, 0.1404164811277527, 133]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 3.6800\n",
      "Function value obtained: -0.8778\n",
      "Current minimum: -0.9458\n"
     ]
    }
   ],
   "source": [
    "def tuneLGBM(params):\n",
    "    print(params)\n",
    "    lr = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    n_estimators = params[5]\n",
    "    \n",
    "    dictParams = {'learning_rate': lr,\n",
    "                 'max_depth': max_depth,\n",
    "                 'min_child_samples': min_child_samples,\n",
    "                 'subsample': subsample,\n",
    "                 'colsample_bytree': colsample_bytree,\n",
    "                 'n_estimators': n_estimators}\n",
    "    \n",
    "    modelName = 'Lightgbm Classifier'\n",
    "    kfold = 10\n",
    "    \n",
    "    precisionList = []\n",
    "    recallList = []\n",
    "    f1List = []\n",
    "    kappaList = []\n",
    "    apList = []\n",
    "    rocaucList = []\n",
    "    paramList =[]\n",
    "    XTraining = dfTrain.sample(frac=1).reset_index(drop=True)\n",
    "    for k in reversed(range(1, kfold+1)):\n",
    "        \n",
    "        # Filtering Dataset\n",
    "        training = XTraining.iloc[0: k*(round(XTraining.shape[0]/(kfold+1))), :]\n",
    "        validation = XTraining.iloc[k*(round(XTraining.shape[0]/(kfold+1))) : (k+1)*(round(XTraining.shape[0]/(kfold+1))), :]\n",
    "\n",
    "        # Training and Validation Dataset\n",
    "        # Training\n",
    "        XKFoldTraining = training.drop(['Exited'], axis=1)\n",
    "        yKFoldTraining = training['Exited']\n",
    "\n",
    "        # Validation\n",
    "        XKFoldValidation = validation.drop(['Exited'], axis=1)\n",
    "        yKFoldValidation = validation['Exited']\n",
    "        \n",
    "        \n",
    "    \n",
    "        model = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                               min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                               bagging_freq=1, n_estimators=n_estimators, random_state=0, class_weight='balanced', n_jobs=-1)\n",
    "    \n",
    "    \n",
    "        #Model\n",
    "        model.fit(XKFoldTraining, yKFoldTraining)\n",
    "    \n",
    "           # Prediction\n",
    "        yhat = model.predict(XKFoldValidation)\n",
    "        \n",
    "        # Prediction Proba\n",
    "        yhatProba = model.predict_proba(XKFoldValidation)[:,1]\n",
    "                #Performance\n",
    "        modelResult = mlScores(modelName, yKFoldValidation, yhat, yhatProba)\n",
    "        \n",
    "        #Store Performance of each KFold iteration\n",
    "        precisionList.append(modelResult['Precision'].tolist())\n",
    "        recallList.append(modelResult['Recall'].tolist())\n",
    "        f1List.append(modelResult['F1 Score'].tolist())\n",
    "        kappaList.append(modelResult['Kappa'].tolist())\n",
    "        apList.append(modelResult['Average Precision Score'].tolist())\n",
    "        rocaucList.append(modelResult['ROC AUC'].tolist())\n",
    "        paramList.append(dictParams)\n",
    "    \n",
    "\n",
    "    dictResult = {\n",
    "                    'Model Name': [modelName],\n",
    "                    'Precision CV': [np.round(np.mean(precisionList),4).astype(str) + ' +/- ' + np.round(np.std(precisionList),4).astype(str)],\n",
    "                    'Recall CV': [np.round(np.mean(recallList),4).astype(str) + ' +/- ' + np.round(np.std(recallList),4).astype(str)],\n",
    "                    'F1 Score CV': [np.round(np.mean(f1List),4).astype(str) + ' +/- ' + np.round(np.std(f1List),4).astype(str)],\n",
    "                    'Kappa CV': [np.round(np.mean(kappaList),4).astype(str) + ' +/- ' + np.round(np.std(kappaList),4).astype(str)],\n",
    "                    'Average Precision Score CV': [np.round(np.mean(apList),4).astype(str) + ' +/- ' + np.round(np.std(apList),4).astype(str)],\n",
    "                    'ROC AUC CV': [np.round(np.mean(rocaucList),4).astype(str) + ' +/- ' + np.round(np.std(rocaucList),4).astype(str)],\n",
    "                    'Params': [paramList]\n",
    "                }\n",
    "\n",
    "    \n",
    "    dfmetrics = pd.DataFrame(dictResult)\n",
    "    global dfResultsLGBM\n",
    "    dfResultsLGBM = pd.concat([dfmetrics, dfResultsLGBM], axis=0)\n",
    "    \n",
    "    return -np.mean(apList)\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), #lr\n",
    "        (1, 10), #max_depth\n",
    "        (1, 20), #min_child_samples\n",
    "        (0.05, 1.0), #subsample\n",
    "        (0.05, 1.0), #colsample_bytree\n",
    "        (100, 1200)] #n_estimetors\n",
    "\n",
    "\n",
    "\n",
    "result = forest_minimize(tuneLGBM, space, random_state=160745, n_random_starts=20, n_calls=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.016490254525097375, 9, 9, 0.6502182010234373, 0.6866210554187129, 1069]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultLGBM = result.x\n",
    "resultLGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision CV</th>\n",
       "      <th>Recall CV</th>\n",
       "      <th>F1 Score CV</th>\n",
       "      <th>Kappa CV</th>\n",
       "      <th>Average Precision Score CV</th>\n",
       "      <th>ROC AUC CV</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8134 +/- 0.0183</td>\n",
       "      <td>0.7987 +/- 0.0219</td>\n",
       "      <td>0.8058 +/- 0.0169</td>\n",
       "      <td>0.6146 +/- 0.0289</td>\n",
       "      <td>0.8778 +/- 0.0123</td>\n",
       "      <td>0.8799 +/- 0.0103</td>\n",
       "      <td>[{'learning_rate': 0.018353598126553926, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8724 +/- 0.0257</td>\n",
       "      <td>0.8214 +/- 0.0203</td>\n",
       "      <td>0.8461 +/- 0.022</td>\n",
       "      <td>0.7003 +/- 0.0467</td>\n",
       "      <td>0.9371 +/- 0.0173</td>\n",
       "      <td>0.9217 +/- 0.0208</td>\n",
       "      <td>[{'learning_rate': 0.07698616486747904, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8359 +/- 0.0233</td>\n",
       "      <td>0.8001 +/- 0.0288</td>\n",
       "      <td>0.8175 +/- 0.0252</td>\n",
       "      <td>0.6442 +/- 0.048</td>\n",
       "      <td>0.8943 +/- 0.014</td>\n",
       "      <td>0.897 +/- 0.0154</td>\n",
       "      <td>[{'learning_rate': 0.005545743892663144, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.7917 +/- 0.0194</td>\n",
       "      <td>0.7511 +/- 0.0162</td>\n",
       "      <td>0.7707 +/- 0.0126</td>\n",
       "      <td>0.5521 +/- 0.0184</td>\n",
       "      <td>0.8606 +/- 0.0127</td>\n",
       "      <td>0.8588 +/- 0.0076</td>\n",
       "      <td>[{'learning_rate': 0.017293945600511968, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8702 +/- 0.0241</td>\n",
       "      <td>0.8436 +/- 0.0301</td>\n",
       "      <td>0.8566 +/- 0.0253</td>\n",
       "      <td>0.7172 +/- 0.0494</td>\n",
       "      <td>0.9386 +/- 0.0206</td>\n",
       "      <td>0.9345 +/- 0.0197</td>\n",
       "      <td>[{'learning_rate': 0.07153671917186938, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.839 +/- 0.0253</td>\n",
       "      <td>0.825 +/- 0.0164</td>\n",
       "      <td>0.8318 +/- 0.0185</td>\n",
       "      <td>0.666 +/- 0.0424</td>\n",
       "      <td>0.9064 +/- 0.0172</td>\n",
       "      <td>0.9066 +/- 0.0172</td>\n",
       "      <td>[{'learning_rate': 0.028323043345821718, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8736 +/- 0.025</td>\n",
       "      <td>0.8184 +/- 0.0185</td>\n",
       "      <td>0.845 +/- 0.0199</td>\n",
       "      <td>0.7005 +/- 0.0431</td>\n",
       "      <td>0.9355 +/- 0.0195</td>\n",
       "      <td>0.9233 +/- 0.0217</td>\n",
       "      <td>[{'learning_rate': 0.041299973169667735, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8516 +/- 0.0165</td>\n",
       "      <td>0.8201 +/- 0.0189</td>\n",
       "      <td>0.8354 +/- 0.0156</td>\n",
       "      <td>0.6766 +/- 0.0299</td>\n",
       "      <td>0.9139 +/- 0.0149</td>\n",
       "      <td>0.9133 +/- 0.0147</td>\n",
       "      <td>[{'learning_rate': 0.01028491314690704, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8381 +/- 0.0345</td>\n",
       "      <td>0.807 +/- 0.0229</td>\n",
       "      <td>0.8222 +/- 0.0278</td>\n",
       "      <td>0.6504 +/- 0.0555</td>\n",
       "      <td>0.9029 +/- 0.0221</td>\n",
       "      <td>0.9017 +/- 0.0208</td>\n",
       "      <td>[{'learning_rate': 0.0010815024957285871, 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8326 +/- 0.0189</td>\n",
       "      <td>0.8128 +/- 0.0238</td>\n",
       "      <td>0.8224 +/- 0.0172</td>\n",
       "      <td>0.6487 +/- 0.0382</td>\n",
       "      <td>0.8977 +/- 0.0112</td>\n",
       "      <td>0.8976 +/- 0.013</td>\n",
       "      <td>[{'learning_rate': 0.00254165132488824, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8405 +/- 0.0284</td>\n",
       "      <td>0.7729 +/- 0.0342</td>\n",
       "      <td>0.8049 +/- 0.0275</td>\n",
       "      <td>0.6264 +/- 0.0535</td>\n",
       "      <td>0.8873 +/- 0.0244</td>\n",
       "      <td>0.8908 +/- 0.0198</td>\n",
       "      <td>[{'learning_rate': 0.0016477897665487307, 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8097 +/- 0.0227</td>\n",
       "      <td>0.7675 +/- 0.0136</td>\n",
       "      <td>0.7878 +/- 0.0117</td>\n",
       "      <td>0.5883 +/- 0.0206</td>\n",
       "      <td>0.8697 +/- 0.0142</td>\n",
       "      <td>0.8739 +/- 0.0111</td>\n",
       "      <td>[{'learning_rate': 0.009780455975240894, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.7733 +/- 0.0091</td>\n",
       "      <td>0.7425 +/- 0.0195</td>\n",
       "      <td>0.7575 +/- 0.0121</td>\n",
       "      <td>0.5257 +/- 0.0236</td>\n",
       "      <td>0.8391 +/- 0.0134</td>\n",
       "      <td>0.8406 +/- 0.0114</td>\n",
       "      <td>[{'learning_rate': 0.005883946521405699, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8725 +/- 0.0269</td>\n",
       "      <td>0.8461 +/- 0.0192</td>\n",
       "      <td>0.8591 +/- 0.022</td>\n",
       "      <td>0.7217 +/- 0.0412</td>\n",
       "      <td>0.9388 +/- 0.0215</td>\n",
       "      <td>0.9349 +/- 0.019</td>\n",
       "      <td>[{'learning_rate': 0.02614950849523158, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.7157 +/- 0.0288</td>\n",
       "      <td>0.6952 +/- 0.0427</td>\n",
       "      <td>0.7039 +/- 0.0195</td>\n",
       "      <td>0.4156 +/- 0.0309</td>\n",
       "      <td>0.696 +/- 0.024</td>\n",
       "      <td>0.7425 +/- 0.016</td>\n",
       "      <td>[{'learning_rate': 0.0014836076428283468, 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8494 +/- 0.0381</td>\n",
       "      <td>0.8488 +/- 0.0302</td>\n",
       "      <td>0.8489 +/- 0.0312</td>\n",
       "      <td>0.6981 +/- 0.0656</td>\n",
       "      <td>0.9245 +/- 0.026</td>\n",
       "      <td>0.9224 +/- 0.0261</td>\n",
       "      <td>[{'learning_rate': 0.01834425482425403, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8838 +/- 0.0192</td>\n",
       "      <td>0.8497 +/- 0.0266</td>\n",
       "      <td>0.8663 +/- 0.0213</td>\n",
       "      <td>0.7375 +/- 0.0422</td>\n",
       "      <td>0.9458 +/- 0.0189</td>\n",
       "      <td>0.9396 +/- 0.0182</td>\n",
       "      <td>[{'learning_rate': 0.016490254525097375, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8249 +/- 0.0256</td>\n",
       "      <td>0.8038 +/- 0.0269</td>\n",
       "      <td>0.814 +/- 0.0235</td>\n",
       "      <td>0.6332 +/- 0.0478</td>\n",
       "      <td>0.8924 +/- 0.02</td>\n",
       "      <td>0.8936 +/- 0.021</td>\n",
       "      <td>[{'learning_rate': 0.01250618338439657, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.7493 +/- 0.0211</td>\n",
       "      <td>0.7184 +/- 0.0248</td>\n",
       "      <td>0.7331 +/- 0.0142</td>\n",
       "      <td>0.4771 +/- 0.0242</td>\n",
       "      <td>0.8112 +/- 0.0169</td>\n",
       "      <td>0.822 +/- 0.0084</td>\n",
       "      <td>[{'learning_rate': 0.0010385556240017917, 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8424 +/- 0.0162</td>\n",
       "      <td>0.8011 +/- 0.0157</td>\n",
       "      <td>0.8212 +/- 0.0138</td>\n",
       "      <td>0.651 +/- 0.0258</td>\n",
       "      <td>0.8938 +/- 0.0118</td>\n",
       "      <td>0.8994 +/- 0.0104</td>\n",
       "      <td>[{'learning_rate': 0.009944912110647982, 'max_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name       Precision CV          Recall CV        F1 Score CV           Kappa CV Average Precision Score CV         ROC AUC CV                                             Params\n",
       "0  Lightgbm Classifier  0.8134 +/- 0.0183  0.7987 +/- 0.0219  0.8058 +/- 0.0169  0.6146 +/- 0.0289          0.8778 +/- 0.0123  0.8799 +/- 0.0103  [{'learning_rate': 0.018353598126553926, 'max_...\n",
       "0  Lightgbm Classifier  0.8724 +/- 0.0257  0.8214 +/- 0.0203   0.8461 +/- 0.022  0.7003 +/- 0.0467          0.9371 +/- 0.0173  0.9217 +/- 0.0208  [{'learning_rate': 0.07698616486747904, 'max_d...\n",
       "0  Lightgbm Classifier  0.8359 +/- 0.0233  0.8001 +/- 0.0288  0.8175 +/- 0.0252   0.6442 +/- 0.048           0.8943 +/- 0.014   0.897 +/- 0.0154  [{'learning_rate': 0.005545743892663144, 'max_...\n",
       "0  Lightgbm Classifier  0.7917 +/- 0.0194  0.7511 +/- 0.0162  0.7707 +/- 0.0126  0.5521 +/- 0.0184          0.8606 +/- 0.0127  0.8588 +/- 0.0076  [{'learning_rate': 0.017293945600511968, 'max_...\n",
       "0  Lightgbm Classifier  0.8702 +/- 0.0241  0.8436 +/- 0.0301  0.8566 +/- 0.0253  0.7172 +/- 0.0494          0.9386 +/- 0.0206  0.9345 +/- 0.0197  [{'learning_rate': 0.07153671917186938, 'max_d...\n",
       "0  Lightgbm Classifier   0.839 +/- 0.0253   0.825 +/- 0.0164  0.8318 +/- 0.0185   0.666 +/- 0.0424          0.9064 +/- 0.0172  0.9066 +/- 0.0172  [{'learning_rate': 0.028323043345821718, 'max_...\n",
       "0  Lightgbm Classifier   0.8736 +/- 0.025  0.8184 +/- 0.0185   0.845 +/- 0.0199  0.7005 +/- 0.0431          0.9355 +/- 0.0195  0.9233 +/- 0.0217  [{'learning_rate': 0.041299973169667735, 'max_...\n",
       "0  Lightgbm Classifier  0.8516 +/- 0.0165  0.8201 +/- 0.0189  0.8354 +/- 0.0156  0.6766 +/- 0.0299          0.9139 +/- 0.0149  0.9133 +/- 0.0147  [{'learning_rate': 0.01028491314690704, 'max_d...\n",
       "0  Lightgbm Classifier  0.8381 +/- 0.0345   0.807 +/- 0.0229  0.8222 +/- 0.0278  0.6504 +/- 0.0555          0.9029 +/- 0.0221  0.9017 +/- 0.0208  [{'learning_rate': 0.0010815024957285871, 'max...\n",
       "0  Lightgbm Classifier  0.8326 +/- 0.0189  0.8128 +/- 0.0238  0.8224 +/- 0.0172  0.6487 +/- 0.0382          0.8977 +/- 0.0112   0.8976 +/- 0.013  [{'learning_rate': 0.00254165132488824, 'max_d...\n",
       "0  Lightgbm Classifier  0.8405 +/- 0.0284  0.7729 +/- 0.0342  0.8049 +/- 0.0275  0.6264 +/- 0.0535          0.8873 +/- 0.0244  0.8908 +/- 0.0198  [{'learning_rate': 0.0016477897665487307, 'max...\n",
       "0  Lightgbm Classifier  0.8097 +/- 0.0227  0.7675 +/- 0.0136  0.7878 +/- 0.0117  0.5883 +/- 0.0206          0.8697 +/- 0.0142  0.8739 +/- 0.0111  [{'learning_rate': 0.009780455975240894, 'max_...\n",
       "0  Lightgbm Classifier  0.7733 +/- 0.0091  0.7425 +/- 0.0195  0.7575 +/- 0.0121  0.5257 +/- 0.0236          0.8391 +/- 0.0134  0.8406 +/- 0.0114  [{'learning_rate': 0.005883946521405699, 'max_...\n",
       "0  Lightgbm Classifier  0.8725 +/- 0.0269  0.8461 +/- 0.0192   0.8591 +/- 0.022  0.7217 +/- 0.0412          0.9388 +/- 0.0215   0.9349 +/- 0.019  [{'learning_rate': 0.02614950849523158, 'max_d...\n",
       "0  Lightgbm Classifier  0.7157 +/- 0.0288  0.6952 +/- 0.0427  0.7039 +/- 0.0195  0.4156 +/- 0.0309            0.696 +/- 0.024   0.7425 +/- 0.016  [{'learning_rate': 0.0014836076428283468, 'max...\n",
       "0  Lightgbm Classifier  0.8494 +/- 0.0381  0.8488 +/- 0.0302  0.8489 +/- 0.0312  0.6981 +/- 0.0656           0.9245 +/- 0.026  0.9224 +/- 0.0261  [{'learning_rate': 0.01834425482425403, 'max_d...\n",
       "0  Lightgbm Classifier  0.8838 +/- 0.0192  0.8497 +/- 0.0266  0.8663 +/- 0.0213  0.7375 +/- 0.0422          0.9458 +/- 0.0189  0.9396 +/- 0.0182  [{'learning_rate': 0.016490254525097375, 'max_...\n",
       "0  Lightgbm Classifier  0.8249 +/- 0.0256  0.8038 +/- 0.0269   0.814 +/- 0.0235  0.6332 +/- 0.0478            0.8924 +/- 0.02   0.8936 +/- 0.021  [{'learning_rate': 0.01250618338439657, 'max_d...\n",
       "0  Lightgbm Classifier  0.7493 +/- 0.0211  0.7184 +/- 0.0248  0.7331 +/- 0.0142  0.4771 +/- 0.0242          0.8112 +/- 0.0169   0.822 +/- 0.0084  [{'learning_rate': 0.0010385556240017917, 'max...\n",
       "0  Lightgbm Classifier  0.8424 +/- 0.0162  0.8011 +/- 0.0157  0.8212 +/- 0.0138   0.651 +/- 0.0258          0.8938 +/- 0.0118  0.8994 +/- 0.0104  [{'learning_rate': 0.009944912110647982, 'max_..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResultsLGBM.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[5, 16, 1064]\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 76.5887\n",
      "Function value obtained: -0.8648\n",
      "Current minimum: -0.8648\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[1, 9, 272]\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 17.5262\n",
      "Function value obtained: -0.7981\n",
      "Current minimum: -0.8648\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[9, 2, 269]\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 22.2765\n",
      "Function value obtained: -0.8906\n",
      "Current minimum: -0.8906\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[1, 15, 1006]\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 65.6767\n",
      "Function value obtained: -0.7824\n",
      "Current minimum: -0.8906\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[6, 2, 1134]\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 78.0994\n",
      "Function value obtained: -0.8758\n",
      "Current minimum: -0.8906\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[5, 6, 183]\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 10.2097\n",
      "Function value obtained: -0.8675\n",
      "Current minimum: -0.8906\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[7, 14, 908]\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 48.8945\n",
      "Function value obtained: -0.8794\n",
      "Current minimum: -0.8906\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[8, 12, 670]\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 40.7297\n",
      "Function value obtained: -0.8834\n",
      "Current minimum: -0.8906\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[9, 9, 748]\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 42.0506\n",
      "Function value obtained: -0.8895\n",
      "Current minimum: -0.8906\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[2, 10, 880]\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 42.6999\n",
      "Function value obtained: -0.8224\n",
      "Current minimum: -0.8906\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[10, 1, 491]\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 29.2303\n",
      "Function value obtained: -0.8994\n",
      "Current minimum: -0.8994\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[3, 5, 1182]\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 59.3545\n",
      "Function value obtained: -0.8346\n",
      "Current minimum: -0.8994\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[6, 12, 995]\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 53.9400\n",
      "Function value obtained: -0.8732\n",
      "Current minimum: -0.8994\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[1, 13, 414]\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 20.6351\n",
      "Function value obtained: -0.7833\n",
      "Current minimum: -0.8994\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[10, 19, 588]\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 33.2399\n",
      "Function value obtained: -0.8807\n",
      "Current minimum: -0.8994\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[10, 5, 939]\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 54.5795\n",
      "Function value obtained: -0.8929\n",
      "Current minimum: -0.8994\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[4, 15, 406]\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 20.4500\n",
      "Function value obtained: -0.8556\n",
      "Current minimum: -0.8994\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[5, 14, 1057]\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 53.2298\n",
      "Function value obtained: -0.8668\n",
      "Current minimum: -0.8994\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[10, 1, 1050]\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 65.1148\n",
      "Function value obtained: -0.9000\n",
      "Current minimum: -0.9000\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[7, 15, 1012]\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 54.0499\n",
      "Function value obtained: -0.8779\n",
      "Current minimum: -0.9000\n"
     ]
    }
   ],
   "source": [
    "def tuneRF(params):\n",
    "    print(params)\n",
    "    max_depth = params[0]\n",
    "    min_samples_leaf = params[1]\n",
    "    n_estimators = params[2]\n",
    "    \n",
    "    dictParams = {'max_depth': max_depth,\n",
    "                  'min_samples_leaf': min_samples_leaf,\n",
    "                  'n_estimators': n_estimators}\n",
    "    \n",
    "    \n",
    "    modelName = 'Random Forest Classifier'\n",
    "    kfold = 10\n",
    "    \n",
    "    precisionList = []\n",
    "    recallList = []\n",
    "    f1List = []\n",
    "    kappaList = []\n",
    "    apList = []\n",
    "    rocaucList = []\n",
    "    paramList =[]\n",
    "    XTraining = dfTrain.sample(frac=1).reset_index(drop=True)\n",
    "    for k in reversed(range(1, kfold+1)):\n",
    "        \n",
    "        # Filtering Dataset\n",
    "        training = XTraining.iloc[0: k*(round(XTraining.shape[0]/(kfold+1))), :]\n",
    "        validation = XTraining.iloc[k*(round(XTraining.shape[0]/(kfold+1))) : (k+1)*(round(XTraining.shape[0]/(kfold+1))), :]\n",
    "\n",
    "        # Training and Validation Dataset\n",
    "        # Training\n",
    "        XKFoldTraining = training.drop(['Exited'], axis=1)\n",
    "        yKFoldTraining = training['Exited']\n",
    "\n",
    "        # Validation\n",
    "        XKFoldValidation = validation.drop(['Exited'], axis=1)\n",
    "        yKFoldValidation = validation['Exited']\n",
    "        \n",
    "        \n",
    "        #Model\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=0,\n",
    "                                           class_weight='balanced', n_jobs=-1)\n",
    "    \n",
    "    \n",
    "        \n",
    "        model.fit(XKFoldTraining, yKFoldTraining)\n",
    "    \n",
    "           # Prediction\n",
    "        yhat = model.predict(XKFoldValidation)\n",
    "        \n",
    "        # Prediction Proba\n",
    "        yhatProba = model.predict_proba(XKFoldValidation)[:,1]\n",
    "                #Performance\n",
    "        modelResult = mlScores(modelName, yKFoldValidation, yhat, yhatProba)\n",
    "        \n",
    "        #Store Performance of each KFold iteration\n",
    "        precisionList.append(modelResult['Precision'].tolist())\n",
    "        recallList.append(modelResult['Recall'].tolist())\n",
    "        f1List.append(modelResult['F1 Score'].tolist())\n",
    "        kappaList.append(modelResult['Kappa'].tolist())\n",
    "        apList.append(modelResult['Average Precision Score'].tolist())\n",
    "        rocaucList.append(modelResult['ROC AUC'].tolist())\n",
    "        paramList.append(dictParams)\n",
    "\n",
    "    dictResult = {\n",
    "                    'Model Name': [modelName],\n",
    "                    'Precision CV': [np.round(np.mean(precisionList),2).astype(str) + ' +/- ' + np.round(np.std(precisionList),2).astype(str)],\n",
    "                    'Recall CV': [np.round(np.mean(recallList),2).astype(str) + ' +/- ' + np.round(np.std(recallList),2).astype(str)],\n",
    "                    'F1 Score CV': [np.round(np.mean(f1List),2).astype(str) + ' +/- ' + np.round(np.std(f1List),2).astype(str)],\n",
    "                    'Kappa CV': [np.round(np.mean(kappaList),2).astype(str) + ' +/- ' + np.round(np.std(kappaList),2).astype(str)],\n",
    "                    'Average Precision Score CV': [np.round(np.mean(apList),2).astype(str) + ' +/- ' + np.round(np.std(apList),2).astype(str)],\n",
    "                    'ROC AUC CV': [np.round(np.mean(rocaucList),2).astype(str) + ' +/- ' + np.round(np.std(rocaucList),2).astype(str)],\n",
    "                    'Params': [paramList]\n",
    "                }\n",
    "\n",
    "    \n",
    "    dfmetrics = pd.DataFrame(dictResult)\n",
    "    global dfResultsRF\n",
    "    dfResultsRF = pd.concat([dfmetrics, dfResultsRF], axis=0)\n",
    "    \n",
    "    return -np.mean(apList)\n",
    "\n",
    "space = [(1, 10), #max_depth\n",
    "        (1, 20), #min_samples_leaf \n",
    "        (100, 1200)] #n_estimetors\n",
    "\n",
    "\n",
    "\n",
    "result = forest_minimize(tuneRF, space, random_state=160745, n_random_starts=20, n_calls=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 1, 1050]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultRF = result.x\n",
    "resultRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision CV</th>\n",
       "      <th>Recall CV</th>\n",
       "      <th>F1 Score CV</th>\n",
       "      <th>Kappa CV</th>\n",
       "      <th>Average Precision Score CV</th>\n",
       "      <th>ROC AUC CV</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.81 +/- 0.03</td>\n",
       "      <td>0.76 +/- 0.02</td>\n",
       "      <td>0.78 +/- 0.01</td>\n",
       "      <td>0.58 +/- 0.03</td>\n",
       "      <td>0.88 +/- 0.02</td>\n",
       "      <td>0.88 +/- 0.02</td>\n",
       "      <td>[{'max_depth': 7, 'min_samples_leaf': 15, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.83 +/- 0.02</td>\n",
       "      <td>0.81 +/- 0.02</td>\n",
       "      <td>0.82 +/- 0.02</td>\n",
       "      <td>0.65 +/- 0.03</td>\n",
       "      <td>0.9 +/- 0.02</td>\n",
       "      <td>0.9 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 10, 'min_samples_leaf': 1, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.81 +/- 0.02</td>\n",
       "      <td>0.74 +/- 0.02</td>\n",
       "      <td>0.77 +/- 0.02</td>\n",
       "      <td>0.56 +/- 0.03</td>\n",
       "      <td>0.87 +/- 0.02</td>\n",
       "      <td>0.87 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 5, 'min_samples_leaf': 14, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.79 +/- 0.03</td>\n",
       "      <td>0.72 +/- 0.02</td>\n",
       "      <td>0.76 +/- 0.01</td>\n",
       "      <td>0.53 +/- 0.02</td>\n",
       "      <td>0.86 +/- 0.02</td>\n",
       "      <td>0.86 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 4, 'min_samples_leaf': 15, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.83 +/- 0.01</td>\n",
       "      <td>0.8 +/- 0.03</td>\n",
       "      <td>0.81 +/- 0.02</td>\n",
       "      <td>0.63 +/- 0.04</td>\n",
       "      <td>0.89 +/- 0.01</td>\n",
       "      <td>0.9 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 10, 'min_samples_leaf': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.82 +/- 0.03</td>\n",
       "      <td>0.79 +/- 0.03</td>\n",
       "      <td>0.8 +/- 0.02</td>\n",
       "      <td>0.61 +/- 0.05</td>\n",
       "      <td>0.88 +/- 0.02</td>\n",
       "      <td>0.88 +/- 0.02</td>\n",
       "      <td>[{'max_depth': 10, 'min_samples_leaf': 19, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.73 +/- 0.02</td>\n",
       "      <td>0.67 +/- 0.03</td>\n",
       "      <td>0.7 +/- 0.02</td>\n",
       "      <td>0.43 +/- 0.03</td>\n",
       "      <td>0.78 +/- 0.03</td>\n",
       "      <td>0.8 +/- 0.02</td>\n",
       "      <td>[{'max_depth': 1, 'min_samples_leaf': 13, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.81 +/- 0.02</td>\n",
       "      <td>0.74 +/- 0.01</td>\n",
       "      <td>0.78 +/- 0.01</td>\n",
       "      <td>0.57 +/- 0.02</td>\n",
       "      <td>0.87 +/- 0.02</td>\n",
       "      <td>0.87 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 6, 'min_samples_leaf': 12, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.78 +/- 0.03</td>\n",
       "      <td>0.72 +/- 0.04</td>\n",
       "      <td>0.75 +/- 0.02</td>\n",
       "      <td>0.52 +/- 0.03</td>\n",
       "      <td>0.83 +/- 0.02</td>\n",
       "      <td>0.84 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 3, 'min_samples_leaf': 5, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.83 +/- 0.02</td>\n",
       "      <td>0.81 +/- 0.01</td>\n",
       "      <td>0.82 +/- 0.01</td>\n",
       "      <td>0.64 +/- 0.03</td>\n",
       "      <td>0.9 +/- 0.02</td>\n",
       "      <td>0.9 +/- 0.02</td>\n",
       "      <td>[{'max_depth': 10, 'min_samples_leaf': 1, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.76 +/- 0.02</td>\n",
       "      <td>0.76 +/- 0.03</td>\n",
       "      <td>0.76 +/- 0.02</td>\n",
       "      <td>0.51 +/- 0.03</td>\n",
       "      <td>0.82 +/- 0.02</td>\n",
       "      <td>0.82 +/- 0.02</td>\n",
       "      <td>[{'max_depth': 2, 'min_samples_leaf': 10, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.82 +/- 0.01</td>\n",
       "      <td>0.8 +/- 0.03</td>\n",
       "      <td>0.81 +/- 0.02</td>\n",
       "      <td>0.62 +/- 0.04</td>\n",
       "      <td>0.89 +/- 0.02</td>\n",
       "      <td>0.89 +/- 0.02</td>\n",
       "      <td>[{'max_depth': 9, 'min_samples_leaf': 9, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.82 +/- 0.01</td>\n",
       "      <td>0.77 +/- 0.03</td>\n",
       "      <td>0.8 +/- 0.02</td>\n",
       "      <td>0.61 +/- 0.03</td>\n",
       "      <td>0.88 +/- 0.02</td>\n",
       "      <td>0.89 +/- 0.02</td>\n",
       "      <td>[{'max_depth': 8, 'min_samples_leaf': 12, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.82 +/- 0.01</td>\n",
       "      <td>0.76 +/- 0.02</td>\n",
       "      <td>0.79 +/- 0.01</td>\n",
       "      <td>0.59 +/- 0.03</td>\n",
       "      <td>0.88 +/- 0.01</td>\n",
       "      <td>0.88 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 7, 'min_samples_leaf': 14, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.81 +/- 0.01</td>\n",
       "      <td>0.75 +/- 0.01</td>\n",
       "      <td>0.77 +/- 0.01</td>\n",
       "      <td>0.56 +/- 0.02</td>\n",
       "      <td>0.87 +/- 0.01</td>\n",
       "      <td>0.87 +/- 0.0</td>\n",
       "      <td>[{'max_depth': 5, 'min_samples_leaf': 6, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.82 +/- 0.02</td>\n",
       "      <td>0.75 +/- 0.01</td>\n",
       "      <td>0.78 +/- 0.01</td>\n",
       "      <td>0.58 +/- 0.02</td>\n",
       "      <td>0.88 +/- 0.01</td>\n",
       "      <td>0.88 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 6, 'min_samples_leaf': 2, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.72 +/- 0.01</td>\n",
       "      <td>0.7 +/- 0.02</td>\n",
       "      <td>0.71 +/- 0.01</td>\n",
       "      <td>0.44 +/- 0.02</td>\n",
       "      <td>0.78 +/- 0.02</td>\n",
       "      <td>0.8 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 1, 'min_samples_leaf': 15, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.82 +/- 0.02</td>\n",
       "      <td>0.79 +/- 0.02</td>\n",
       "      <td>0.81 +/- 0.02</td>\n",
       "      <td>0.62 +/- 0.03</td>\n",
       "      <td>0.89 +/- 0.02</td>\n",
       "      <td>0.89 +/- 0.02</td>\n",
       "      <td>[{'max_depth': 9, 'min_samples_leaf': 2, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.73 +/- 0.02</td>\n",
       "      <td>0.69 +/- 0.01</td>\n",
       "      <td>0.71 +/- 0.01</td>\n",
       "      <td>0.43 +/- 0.02</td>\n",
       "      <td>0.8 +/- 0.01</td>\n",
       "      <td>0.81 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 1, 'min_samples_leaf': 9, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.8 +/- 0.02</td>\n",
       "      <td>0.75 +/- 0.02</td>\n",
       "      <td>0.78 +/- 0.01</td>\n",
       "      <td>0.56 +/- 0.02</td>\n",
       "      <td>0.86 +/- 0.01</td>\n",
       "      <td>0.86 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 5, 'min_samples_leaf': 16, 'n_e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name   Precision CV      Recall CV    F1 Score CV       Kappa CV Average Precision Score CV     ROC AUC CV                                             Params\n",
       "0  Random Forest Classifier  0.81 +/- 0.03  0.76 +/- 0.02  0.78 +/- 0.01  0.58 +/- 0.03              0.88 +/- 0.02  0.88 +/- 0.02  [{'max_depth': 7, 'min_samples_leaf': 15, 'n_e...\n",
       "0  Random Forest Classifier  0.83 +/- 0.02  0.81 +/- 0.02  0.82 +/- 0.02  0.65 +/- 0.03               0.9 +/- 0.02   0.9 +/- 0.01  [{'max_depth': 10, 'min_samples_leaf': 1, 'n_e...\n",
       "0  Random Forest Classifier  0.81 +/- 0.02  0.74 +/- 0.02  0.77 +/- 0.02  0.56 +/- 0.03              0.87 +/- 0.02  0.87 +/- 0.01  [{'max_depth': 5, 'min_samples_leaf': 14, 'n_e...\n",
       "0  Random Forest Classifier  0.79 +/- 0.03  0.72 +/- 0.02  0.76 +/- 0.01  0.53 +/- 0.02              0.86 +/- 0.02  0.86 +/- 0.01  [{'max_depth': 4, 'min_samples_leaf': 15, 'n_e...\n",
       "0  Random Forest Classifier  0.83 +/- 0.01   0.8 +/- 0.03  0.81 +/- 0.02  0.63 +/- 0.04              0.89 +/- 0.01   0.9 +/- 0.01  [{'max_depth': 10, 'min_samples_leaf': 5, 'n_e...\n",
       "0  Random Forest Classifier  0.82 +/- 0.03  0.79 +/- 0.03   0.8 +/- 0.02  0.61 +/- 0.05              0.88 +/- 0.02  0.88 +/- 0.02  [{'max_depth': 10, 'min_samples_leaf': 19, 'n_...\n",
       "0  Random Forest Classifier  0.73 +/- 0.02  0.67 +/- 0.03   0.7 +/- 0.02  0.43 +/- 0.03              0.78 +/- 0.03   0.8 +/- 0.02  [{'max_depth': 1, 'min_samples_leaf': 13, 'n_e...\n",
       "0  Random Forest Classifier  0.81 +/- 0.02  0.74 +/- 0.01  0.78 +/- 0.01  0.57 +/- 0.02              0.87 +/- 0.02  0.87 +/- 0.01  [{'max_depth': 6, 'min_samples_leaf': 12, 'n_e...\n",
       "0  Random Forest Classifier  0.78 +/- 0.03  0.72 +/- 0.04  0.75 +/- 0.02  0.52 +/- 0.03              0.83 +/- 0.02  0.84 +/- 0.01  [{'max_depth': 3, 'min_samples_leaf': 5, 'n_es...\n",
       "0  Random Forest Classifier  0.83 +/- 0.02  0.81 +/- 0.01  0.82 +/- 0.01  0.64 +/- 0.03               0.9 +/- 0.02   0.9 +/- 0.02  [{'max_depth': 10, 'min_samples_leaf': 1, 'n_e...\n",
       "0  Random Forest Classifier  0.76 +/- 0.02  0.76 +/- 0.03  0.76 +/- 0.02  0.51 +/- 0.03              0.82 +/- 0.02  0.82 +/- 0.02  [{'max_depth': 2, 'min_samples_leaf': 10, 'n_e...\n",
       "0  Random Forest Classifier  0.82 +/- 0.01   0.8 +/- 0.03  0.81 +/- 0.02  0.62 +/- 0.04              0.89 +/- 0.02  0.89 +/- 0.02  [{'max_depth': 9, 'min_samples_leaf': 9, 'n_es...\n",
       "0  Random Forest Classifier  0.82 +/- 0.01  0.77 +/- 0.03   0.8 +/- 0.02  0.61 +/- 0.03              0.88 +/- 0.02  0.89 +/- 0.02  [{'max_depth': 8, 'min_samples_leaf': 12, 'n_e...\n",
       "0  Random Forest Classifier  0.82 +/- 0.01  0.76 +/- 0.02  0.79 +/- 0.01  0.59 +/- 0.03              0.88 +/- 0.01  0.88 +/- 0.01  [{'max_depth': 7, 'min_samples_leaf': 14, 'n_e...\n",
       "0  Random Forest Classifier  0.81 +/- 0.01  0.75 +/- 0.01  0.77 +/- 0.01  0.56 +/- 0.02              0.87 +/- 0.01   0.87 +/- 0.0  [{'max_depth': 5, 'min_samples_leaf': 6, 'n_es...\n",
       "0  Random Forest Classifier  0.82 +/- 0.02  0.75 +/- 0.01  0.78 +/- 0.01  0.58 +/- 0.02              0.88 +/- 0.01  0.88 +/- 0.01  [{'max_depth': 6, 'min_samples_leaf': 2, 'n_es...\n",
       "0  Random Forest Classifier  0.72 +/- 0.01   0.7 +/- 0.02  0.71 +/- 0.01  0.44 +/- 0.02              0.78 +/- 0.02   0.8 +/- 0.01  [{'max_depth': 1, 'min_samples_leaf': 15, 'n_e...\n",
       "0  Random Forest Classifier  0.82 +/- 0.02  0.79 +/- 0.02  0.81 +/- 0.02  0.62 +/- 0.03              0.89 +/- 0.02  0.89 +/- 0.02  [{'max_depth': 9, 'min_samples_leaf': 2, 'n_es...\n",
       "0  Random Forest Classifier  0.73 +/- 0.02  0.69 +/- 0.01  0.71 +/- 0.01  0.43 +/- 0.02               0.8 +/- 0.01  0.81 +/- 0.01  [{'max_depth': 1, 'min_samples_leaf': 9, 'n_es...\n",
       "0  Random Forest Classifier   0.8 +/- 0.02  0.75 +/- 0.02  0.78 +/- 0.01  0.56 +/- 0.02              0.86 +/- 0.01  0.86 +/- 0.01  [{'max_depth': 5, 'min_samples_leaf': 16, 'n_e..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResultsRF.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.009944912110647982, 5, 1, 0.4677107511929402, 0.49263223036174764, 272, 0.004107440468167135]\n",
      "[16:08:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 15.8628\n",
      "Function value obtained: -0.8855\n",
      "Current minimum: -0.8855\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.053887464791860025, 1, 6, 0.20280403175305034, 0.5270541127738826, 450, 0.033090405574685906]\n",
      "[16:08:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 12.6503\n",
      "Function value obtained: -0.8458\n",
      "Current minimum: -0.8855\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.09124677388812386, 7, 9, 0.32628643293470494, 0.3800553986495586, 348, 0.33858005937862634]\n",
      "[16:08:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 15.9926\n",
      "Function value obtained: -0.9013\n",
      "Current minimum: -0.9013\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.002581171760283021, 2, 10, 0.6501625354578521, 0.10208277342628153, 491, 0.1552026837035764]\n",
      "[16:09:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:15] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 17.3415\n",
      "Function value obtained: -0.8353\n",
      "Current minimum: -0.9013\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.004758611359340044, 6, 1, 0.31239887914485304, 0.078212872072331, 414, 0.47908767691540777]\n",
      "[16:09:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:09:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 18.6777\n",
      "Function value obtained: -0.8736\n",
      "Current minimum: -0.9013\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.007990318740531337, 10, 5, 0.22076129610800188, 0.8242914803205513, 1057, 0.19241717920371204]\n",
      "[16:09:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:10:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:10:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:10:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:10:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:10:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:10:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:10:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:10:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:10:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 64.9878\n",
      "Function value obtained: -0.9008\n",
      "Current minimum: -0.9013\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.06867197721040089, 7, 7, 0.811247998237159, 0.6963955932783014, 1012, 0.24758977563235035]\n",
      "[16:10:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:11:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:11:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:11:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:11:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:11:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:11:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 77.2951\n",
      "Function value obtained: -0.9336\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.039104896133016556, 8, 9, 0.399351303640462, 0.21661986152103802, 190, 0.4941166118030382]\n",
      "[16:12:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:15] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 10.0909\n",
      "Function value obtained: -0.8847\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.01909842850485622, 3, 9, 0.15978505272104168, 0.24243008662503635, 601, 0.24000799526119637]\n",
      "[16:12:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 19.2304\n",
      "Function value obtained: -0.8429\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.0045872434520256265, 7, 2, 0.06616307483844217, 0.23025600705315752, 677, 0.1558964365288897]\n",
      "[16:12:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 24.5001\n",
      "Function value obtained: -0.8546\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[0.02434342073269358, 7, 5, 0.394574367546406, 0.47085291730616896, 487, 0.2980800450145263]\n",
      "[16:13:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 29.5119\n",
      "Function value obtained: -0.9160\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[0.00423625491169564, 9, 7, 0.5920927617488252, 0.8640355307978103, 232, 0.09949403076170824]\n",
      "[16:13:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 22.6474\n",
      "Function value obtained: -0.8947\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[0.008461359130633768, 10, 4, 0.4742648255888983, 0.8298764961280024, 1034, 0.1411513447667281]\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 94.5069\n",
      "Function value obtained: -0.9215\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[0.038079098196951294, 4, 5, 0.08212463889621416, 0.9235106056270935, 1137, 0.4489859617472653]\n",
      "[16:15:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 42.4173\n",
      "Function value obtained: -0.8885\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[0.006966549818918933, 6, 8, 0.15621607594420134, 0.3235590455448425, 259, 0.17658800594385568]\n",
      "[16:16:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 11.3731\n",
      "Function value obtained: -0.8424\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[0.06625204097578263, 9, 7, 0.4886035071955117, 0.8899327352662949, 974, 0.07446537752748579]\n",
      "[16:16:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:16:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 83.6731\n",
      "Function value obtained: -0.9319\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[0.013391539602531815, 2, 5, 0.9207218468702302, 0.3435268314628721, 884, 0.004083168208398825]\n",
      "[16:17:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:15] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 33.5555\n",
      "Function value obtained: -0.8593\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[0.05561997885794411, 3, 1, 0.5986306129555693, 0.2504863829866467, 695, 0.4728259457183328]\n",
      "[16:18:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 26.9002\n",
      "Function value obtained: -0.8952\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[0.03398499418546645, 5, 2, 0.4027534665117211, 0.8744623478499286, 1047, 0.3050272440887994]\n",
      "[16:18:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 59.7779\n",
      "Function value obtained: -0.9292\n",
      "Current minimum: -0.9336\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[0.0699516121742407, 9, 6, 0.8287804603180822, 0.6477856515609233, 370, 0.06057685654330215]\n",
      "[16:19:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { bagging_freq, class_weight, num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 37.9834\n",
      "Function value obtained: -0.9379\n",
      "Current minimum: -0.9379\n"
     ]
    }
   ],
   "source": [
    "def tuneXGB(params):\n",
    "    print(params)\n",
    "    lr = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_weight = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    n_estimators = params[5]\n",
    "    gamma = params[6]\n",
    "    \n",
    "    dictParams = {'learning_rate': lr,\n",
    "                 'max_depth': max_depth,\n",
    "                 'min_child_weight': min_child_weight,\n",
    "                 'subsample': subsample,\n",
    "                 'colsample_bytree': colsample_bytree,\n",
    "                 'n_estimators': n_estimators,\n",
    "                 'gamma': gamma}\n",
    "    \n",
    "    modelName = 'XGBoost Classifier'\n",
    "    kfold = 10\n",
    "    \n",
    "    precisionList = []\n",
    "    recallList = []\n",
    "    f1List = []\n",
    "    kappaList = []\n",
    "    apList = []\n",
    "    rocaucList = []\n",
    "    paramList =[]\n",
    "    XTraining = dfTrain.sample(frac=1).reset_index(drop=True)\n",
    "    for k in reversed(range(1, kfold+1)):\n",
    "        \n",
    "        # Filtering Dataset\n",
    "        training = XTraining.iloc[0: k*(round(XTraining.shape[0]/(kfold+1))), :]\n",
    "        validation = XTraining.iloc[k*(round(XTraining.shape[0]/(kfold+1))) : (k+1)*(round(XTraining.shape[0]/(kfold+1))), :]\n",
    "\n",
    "        # Training and Validation Dataset\n",
    "        # Training\n",
    "        XKFoldTraining = training.drop(['Exited'], axis=1)\n",
    "        yKFoldTraining = training['Exited']\n",
    "\n",
    "        # Validation\n",
    "        XKFoldValidation = validation.drop(['Exited'], axis=1)\n",
    "        yKFoldValidation = validation['Exited']\n",
    "        \n",
    "        \n",
    "    \n",
    "        model = XGBClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                               min_child_weight=min_child_weight, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                               bagging_freq=1, n_estimators=n_estimators, random_state=0, class_weight='balanced', gamma=gamma, n_jobs=-1)\n",
    "    \n",
    "    \n",
    "        #Model\n",
    "        model.fit(XKFoldTraining, yKFoldTraining)\n",
    "    \n",
    "           # Prediction\n",
    "        yhat = model.predict(XKFoldValidation)\n",
    "        \n",
    "        # Prediction Proba\n",
    "        yhatProba = model.predict_proba(XKFoldValidation)[:,1]\n",
    "                #Performance\n",
    "        modelResult = mlScores(modelName, yKFoldValidation, yhat, yhatProba)\n",
    "        \n",
    "        #Store Performance of each KFold iteration\n",
    "        precisionList.append(modelResult['Precision'].tolist())\n",
    "        recallList.append(modelResult['Recall'].tolist())\n",
    "        f1List.append(modelResult['F1 Score'].tolist())\n",
    "        kappaList.append(modelResult['Kappa'].tolist())\n",
    "        apList.append(modelResult['Average Precision Score'].tolist())\n",
    "        rocaucList.append(modelResult['ROC AUC'].tolist())\n",
    "        paramList.append(dictParams)\n",
    "    \n",
    "\n",
    "    dictResult = {\n",
    "                    'Model Name': [modelName],\n",
    "                    'Precision CV': [np.round(np.mean(precisionList),4).astype(str) + ' +/- ' + np.round(np.std(precisionList),4).astype(str)],\n",
    "                    'Recall CV': [np.round(np.mean(recallList),4).astype(str) + ' +/- ' + np.round(np.std(recallList),4).astype(str)],\n",
    "                    'F1 Score CV': [np.round(np.mean(f1List),4).astype(str) + ' +/- ' + np.round(np.std(f1List),4).astype(str)],\n",
    "                    'Kappa CV': [np.round(np.mean(kappaList),4).astype(str) + ' +/- ' + np.round(np.std(kappaList),4).astype(str)],\n",
    "                    'Average Precision Score CV': [np.round(np.mean(apList),4).astype(str) + ' +/- ' + np.round(np.std(apList),4).astype(str)],\n",
    "                    'ROC AUC CV': [np.round(np.mean(rocaucList),4).astype(str) + ' +/- ' + np.round(np.std(rocaucList),4).astype(str)],\n",
    "                    'Params': [paramList]\n",
    "                }\n",
    "\n",
    "    \n",
    "    dfmetrics = pd.DataFrame(dictResult)\n",
    "    global dfResultsXGB\n",
    "    dfResultsXGB = pd.concat([dfmetrics, dfResultsXGB], axis=0)\n",
    "    \n",
    "    return -np.mean(apList)\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), #lr\n",
    "        (1, 10), #max_depth\n",
    "        (1, 10), #min_child_weight\n",
    "        (0.05, 1.0), #subsample\n",
    "        (0.05, 1.0), #colsample_bytree\n",
    "        (100, 1200), #n_estimetors\n",
    "        (0.0, 0.5)] #gamma\n",
    "\n",
    "\n",
    "result = forest_minimize(tuneXGB, space, random_state=160745, n_random_starts=20, n_calls=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0699516121742407,\n",
       " 9,\n",
       " 6,\n",
       " 0.8287804603180822,\n",
       " 0.6477856515609233,\n",
       " 370,\n",
       " 0.06057685654330215]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultXGB = result.x\n",
    "resultXGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision CV</th>\n",
       "      <th>Recall CV</th>\n",
       "      <th>F1 Score CV</th>\n",
       "      <th>Kappa CV</th>\n",
       "      <th>Average Precision Score CV</th>\n",
       "      <th>ROC AUC CV</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8732 +/- 0.0229</td>\n",
       "      <td>0.849 +/- 0.0362</td>\n",
       "      <td>0.8607 +/- 0.0278</td>\n",
       "      <td>0.7245 +/- 0.0566</td>\n",
       "      <td>0.9379 +/- 0.0247</td>\n",
       "      <td>0.933 +/- 0.0271</td>\n",
       "      <td>[{'learning_rate': 0.0699516121742407, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8641 +/- 0.0357</td>\n",
       "      <td>0.8466 +/- 0.0216</td>\n",
       "      <td>0.8551 +/- 0.0276</td>\n",
       "      <td>0.7127 +/- 0.0553</td>\n",
       "      <td>0.9292 +/- 0.0344</td>\n",
       "      <td>0.9285 +/- 0.0263</td>\n",
       "      <td>[{'learning_rate': 0.03398499418546645, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8324 +/- 0.0213</td>\n",
       "      <td>0.8063 +/- 0.0266</td>\n",
       "      <td>0.8191 +/- 0.0234</td>\n",
       "      <td>0.644 +/- 0.0375</td>\n",
       "      <td>0.8952 +/- 0.0214</td>\n",
       "      <td>0.8964 +/- 0.0172</td>\n",
       "      <td>[{'learning_rate': 0.05561997885794411, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.7874 +/- 0.0136</td>\n",
       "      <td>0.7586 +/- 0.0168</td>\n",
       "      <td>0.7725 +/- 0.0064</td>\n",
       "      <td>0.5527 +/- 0.0179</td>\n",
       "      <td>0.8593 +/- 0.01</td>\n",
       "      <td>0.859 +/- 0.0069</td>\n",
       "      <td>[{'learning_rate': 0.013391539602531815, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8615 +/- 0.0368</td>\n",
       "      <td>0.8523 +/- 0.0291</td>\n",
       "      <td>0.8567 +/- 0.0312</td>\n",
       "      <td>0.7144 +/- 0.0637</td>\n",
       "      <td>0.9319 +/- 0.0349</td>\n",
       "      <td>0.9298 +/- 0.0291</td>\n",
       "      <td>[{'learning_rate': 0.06625204097578263, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.796 +/- 0.022</td>\n",
       "      <td>0.7131 +/- 0.0357</td>\n",
       "      <td>0.7518 +/- 0.0249</td>\n",
       "      <td>0.5295 +/- 0.043</td>\n",
       "      <td>0.8424 +/- 0.0211</td>\n",
       "      <td>0.848 +/- 0.021</td>\n",
       "      <td>[{'learning_rate': 0.006966549818918933, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8262 +/- 0.0325</td>\n",
       "      <td>0.797 +/- 0.036</td>\n",
       "      <td>0.8112 +/- 0.0333</td>\n",
       "      <td>0.6291 +/- 0.0652</td>\n",
       "      <td>0.8885 +/- 0.0405</td>\n",
       "      <td>0.8916 +/- 0.0343</td>\n",
       "      <td>[{'learning_rate': 0.038079098196951294, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8596 +/- 0.0311</td>\n",
       "      <td>0.8317 +/- 0.031</td>\n",
       "      <td>0.8453 +/- 0.0295</td>\n",
       "      <td>0.6952 +/- 0.0581</td>\n",
       "      <td>0.9215 +/- 0.0276</td>\n",
       "      <td>0.9215 +/- 0.0252</td>\n",
       "      <td>[{'learning_rate': 0.008461359130633768, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8478 +/- 0.0302</td>\n",
       "      <td>0.7901 +/- 0.0219</td>\n",
       "      <td>0.8179 +/- 0.0248</td>\n",
       "      <td>0.6458 +/- 0.0528</td>\n",
       "      <td>0.8947 +/- 0.0234</td>\n",
       "      <td>0.8961 +/- 0.0226</td>\n",
       "      <td>[{'learning_rate': 0.00423625491169564, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8657 +/- 0.0328</td>\n",
       "      <td>0.8146 +/- 0.0261</td>\n",
       "      <td>0.8393 +/- 0.0282</td>\n",
       "      <td>0.6883 +/- 0.0543</td>\n",
       "      <td>0.916 +/- 0.0203</td>\n",
       "      <td>0.9151 +/- 0.0213</td>\n",
       "      <td>[{'learning_rate': 0.02434342073269358, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8102 +/- 0.0288</td>\n",
       "      <td>0.7355 +/- 0.0337</td>\n",
       "      <td>0.7707 +/- 0.0287</td>\n",
       "      <td>0.5628 +/- 0.0534</td>\n",
       "      <td>0.8546 +/- 0.0204</td>\n",
       "      <td>0.8611 +/- 0.0225</td>\n",
       "      <td>[{'learning_rate': 0.0045872434520256265, 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.7728 +/- 0.0274</td>\n",
       "      <td>0.7586 +/- 0.0385</td>\n",
       "      <td>0.7653 +/- 0.0293</td>\n",
       "      <td>0.5377 +/- 0.0519</td>\n",
       "      <td>0.8429 +/- 0.039</td>\n",
       "      <td>0.8478 +/- 0.0325</td>\n",
       "      <td>[{'learning_rate': 0.01909842850485622, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8239 +/- 0.0407</td>\n",
       "      <td>0.7803 +/- 0.0409</td>\n",
       "      <td>0.8014 +/- 0.0391</td>\n",
       "      <td>0.6139 +/- 0.072</td>\n",
       "      <td>0.8847 +/- 0.0347</td>\n",
       "      <td>0.8862 +/- 0.0307</td>\n",
       "      <td>[{'learning_rate': 0.039104896133016556, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8718 +/- 0.0338</td>\n",
       "      <td>0.8463 +/- 0.025</td>\n",
       "      <td>0.8587 +/- 0.0271</td>\n",
       "      <td>0.7212 +/- 0.0585</td>\n",
       "      <td>0.9336 +/- 0.0329</td>\n",
       "      <td>0.9314 +/- 0.0276</td>\n",
       "      <td>[{'learning_rate': 0.06867197721040089, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8416 +/- 0.0214</td>\n",
       "      <td>0.8208 +/- 0.0288</td>\n",
       "      <td>0.8309 +/- 0.0234</td>\n",
       "      <td>0.6647 +/- 0.0483</td>\n",
       "      <td>0.9008 +/- 0.0262</td>\n",
       "      <td>0.9033 +/- 0.0255</td>\n",
       "      <td>[{'learning_rate': 0.007990318740531337, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8312 +/- 0.0336</td>\n",
       "      <td>0.764 +/- 0.0228</td>\n",
       "      <td>0.7961 +/- 0.0262</td>\n",
       "      <td>0.6099 +/- 0.0453</td>\n",
       "      <td>0.8736 +/- 0.0273</td>\n",
       "      <td>0.8825 +/- 0.0208</td>\n",
       "      <td>[{'learning_rate': 0.004758611359340044, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.7848 +/- 0.0123</td>\n",
       "      <td>0.711 +/- 0.0139</td>\n",
       "      <td>0.746 +/- 0.0105</td>\n",
       "      <td>0.5158 +/- 0.0173</td>\n",
       "      <td>0.8353 +/- 0.0159</td>\n",
       "      <td>0.8388 +/- 0.0144</td>\n",
       "      <td>[{'learning_rate': 0.002581171760283021, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8311 +/- 0.0333</td>\n",
       "      <td>0.8173 +/- 0.0276</td>\n",
       "      <td>0.824 +/- 0.0295</td>\n",
       "      <td>0.6493 +/- 0.0674</td>\n",
       "      <td>0.9013 +/- 0.0331</td>\n",
       "      <td>0.9001 +/- 0.031</td>\n",
       "      <td>[{'learning_rate': 0.09124677388812386, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.7687 +/- 0.0367</td>\n",
       "      <td>0.749 +/- 0.0225</td>\n",
       "      <td>0.7584 +/- 0.026</td>\n",
       "      <td>0.5241 +/- 0.0537</td>\n",
       "      <td>0.8458 +/- 0.0323</td>\n",
       "      <td>0.846 +/- 0.0255</td>\n",
       "      <td>[{'learning_rate': 0.053887464791860025, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8222 +/- 0.0128</td>\n",
       "      <td>0.8025 +/- 0.0113</td>\n",
       "      <td>0.8122 +/- 0.0089</td>\n",
       "      <td>0.6288 +/- 0.0159</td>\n",
       "      <td>0.8855 +/- 0.0111</td>\n",
       "      <td>0.8917 +/- 0.0073</td>\n",
       "      <td>[{'learning_rate': 0.009944912110647982, 'max_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Name       Precision CV          Recall CV        F1 Score CV           Kappa CV Average Precision Score CV         ROC AUC CV                                             Params\n",
       "0  XGBoost Classifier  0.8732 +/- 0.0229   0.849 +/- 0.0362  0.8607 +/- 0.0278  0.7245 +/- 0.0566          0.9379 +/- 0.0247   0.933 +/- 0.0271  [{'learning_rate': 0.0699516121742407, 'max_de...\n",
       "0  XGBoost Classifier  0.8641 +/- 0.0357  0.8466 +/- 0.0216  0.8551 +/- 0.0276  0.7127 +/- 0.0553          0.9292 +/- 0.0344  0.9285 +/- 0.0263  [{'learning_rate': 0.03398499418546645, 'max_d...\n",
       "0  XGBoost Classifier  0.8324 +/- 0.0213  0.8063 +/- 0.0266  0.8191 +/- 0.0234   0.644 +/- 0.0375          0.8952 +/- 0.0214  0.8964 +/- 0.0172  [{'learning_rate': 0.05561997885794411, 'max_d...\n",
       "0  XGBoost Classifier  0.7874 +/- 0.0136  0.7586 +/- 0.0168  0.7725 +/- 0.0064  0.5527 +/- 0.0179            0.8593 +/- 0.01   0.859 +/- 0.0069  [{'learning_rate': 0.013391539602531815, 'max_...\n",
       "0  XGBoost Classifier  0.8615 +/- 0.0368  0.8523 +/- 0.0291  0.8567 +/- 0.0312  0.7144 +/- 0.0637          0.9319 +/- 0.0349  0.9298 +/- 0.0291  [{'learning_rate': 0.06625204097578263, 'max_d...\n",
       "0  XGBoost Classifier    0.796 +/- 0.022  0.7131 +/- 0.0357  0.7518 +/- 0.0249   0.5295 +/- 0.043          0.8424 +/- 0.0211    0.848 +/- 0.021  [{'learning_rate': 0.006966549818918933, 'max_...\n",
       "0  XGBoost Classifier  0.8262 +/- 0.0325    0.797 +/- 0.036  0.8112 +/- 0.0333  0.6291 +/- 0.0652          0.8885 +/- 0.0405  0.8916 +/- 0.0343  [{'learning_rate': 0.038079098196951294, 'max_...\n",
       "0  XGBoost Classifier  0.8596 +/- 0.0311   0.8317 +/- 0.031  0.8453 +/- 0.0295  0.6952 +/- 0.0581          0.9215 +/- 0.0276  0.9215 +/- 0.0252  [{'learning_rate': 0.008461359130633768, 'max_...\n",
       "0  XGBoost Classifier  0.8478 +/- 0.0302  0.7901 +/- 0.0219  0.8179 +/- 0.0248  0.6458 +/- 0.0528          0.8947 +/- 0.0234  0.8961 +/- 0.0226  [{'learning_rate': 0.00423625491169564, 'max_d...\n",
       "0  XGBoost Classifier  0.8657 +/- 0.0328  0.8146 +/- 0.0261  0.8393 +/- 0.0282  0.6883 +/- 0.0543           0.916 +/- 0.0203  0.9151 +/- 0.0213  [{'learning_rate': 0.02434342073269358, 'max_d...\n",
       "0  XGBoost Classifier  0.8102 +/- 0.0288  0.7355 +/- 0.0337  0.7707 +/- 0.0287  0.5628 +/- 0.0534          0.8546 +/- 0.0204  0.8611 +/- 0.0225  [{'learning_rate': 0.0045872434520256265, 'max...\n",
       "0  XGBoost Classifier  0.7728 +/- 0.0274  0.7586 +/- 0.0385  0.7653 +/- 0.0293  0.5377 +/- 0.0519           0.8429 +/- 0.039  0.8478 +/- 0.0325  [{'learning_rate': 0.01909842850485622, 'max_d...\n",
       "0  XGBoost Classifier  0.8239 +/- 0.0407  0.7803 +/- 0.0409  0.8014 +/- 0.0391   0.6139 +/- 0.072          0.8847 +/- 0.0347  0.8862 +/- 0.0307  [{'learning_rate': 0.039104896133016556, 'max_...\n",
       "0  XGBoost Classifier  0.8718 +/- 0.0338   0.8463 +/- 0.025  0.8587 +/- 0.0271  0.7212 +/- 0.0585          0.9336 +/- 0.0329  0.9314 +/- 0.0276  [{'learning_rate': 0.06867197721040089, 'max_d...\n",
       "0  XGBoost Classifier  0.8416 +/- 0.0214  0.8208 +/- 0.0288  0.8309 +/- 0.0234  0.6647 +/- 0.0483          0.9008 +/- 0.0262  0.9033 +/- 0.0255  [{'learning_rate': 0.007990318740531337, 'max_...\n",
       "0  XGBoost Classifier  0.8312 +/- 0.0336   0.764 +/- 0.0228  0.7961 +/- 0.0262  0.6099 +/- 0.0453          0.8736 +/- 0.0273  0.8825 +/- 0.0208  [{'learning_rate': 0.004758611359340044, 'max_...\n",
       "0  XGBoost Classifier  0.7848 +/- 0.0123   0.711 +/- 0.0139   0.746 +/- 0.0105  0.5158 +/- 0.0173          0.8353 +/- 0.0159  0.8388 +/- 0.0144  [{'learning_rate': 0.002581171760283021, 'max_...\n",
       "0  XGBoost Classifier  0.8311 +/- 0.0333  0.8173 +/- 0.0276   0.824 +/- 0.0295  0.6493 +/- 0.0674          0.9013 +/- 0.0331   0.9001 +/- 0.031  [{'learning_rate': 0.09124677388812386, 'max_d...\n",
       "0  XGBoost Classifier  0.7687 +/- 0.0367   0.749 +/- 0.0225   0.7584 +/- 0.026  0.5241 +/- 0.0537          0.8458 +/- 0.0323   0.846 +/- 0.0255  [{'learning_rate': 0.053887464791860025, 'max_...\n",
       "0  XGBoost Classifier  0.8222 +/- 0.0128  0.8025 +/- 0.0113  0.8122 +/- 0.0089  0.6288 +/- 0.0159          0.8855 +/- 0.0111  0.8917 +/- 0.0073  [{'learning_rate': 0.009944912110647982, 'max_..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResultsXGB.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResults = pd.concat([dfResultsLGBM, dfResultsRF, dfResultsXGB], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision CV</th>\n",
       "      <th>Recall CV</th>\n",
       "      <th>F1 Score CV</th>\n",
       "      <th>Kappa CV</th>\n",
       "      <th>Average Precision Score CV</th>\n",
       "      <th>ROC AUC CV</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8838 +/- 0.0192</td>\n",
       "      <td>0.8497 +/- 0.0266</td>\n",
       "      <td>0.8663 +/- 0.0213</td>\n",
       "      <td>0.7375 +/- 0.0422</td>\n",
       "      <td>0.9458 +/- 0.0189</td>\n",
       "      <td>0.9396 +/- 0.0182</td>\n",
       "      <td>[{'learning_rate': 0.016490254525097375, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.8732 +/- 0.0229</td>\n",
       "      <td>0.849 +/- 0.0362</td>\n",
       "      <td>0.8607 +/- 0.0278</td>\n",
       "      <td>0.7245 +/- 0.0566</td>\n",
       "      <td>0.9379 +/- 0.0247</td>\n",
       "      <td>0.933 +/- 0.0271</td>\n",
       "      <td>[{'learning_rate': 0.0699516121742407, 'max_de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.78 +/- 0.03</td>\n",
       "      <td>0.72 +/- 0.04</td>\n",
       "      <td>0.75 +/- 0.02</td>\n",
       "      <td>0.52 +/- 0.03</td>\n",
       "      <td>0.83 +/- 0.02</td>\n",
       "      <td>0.84 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 3, 'min_samples_leaf': 5, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.83 +/- 0.02</td>\n",
       "      <td>0.81 +/- 0.02</td>\n",
       "      <td>0.82 +/- 0.02</td>\n",
       "      <td>0.65 +/- 0.03</td>\n",
       "      <td>0.9 +/- 0.02</td>\n",
       "      <td>0.9 +/- 0.01</td>\n",
       "      <td>[{'max_depth': 10, 'min_samples_leaf': 1, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lightgbm Classifier</td>\n",
       "      <td>0.8736 +/- 0.025</td>\n",
       "      <td>0.8184 +/- 0.0185</td>\n",
       "      <td>0.845 +/- 0.0199</td>\n",
       "      <td>0.7005 +/- 0.0431</td>\n",
       "      <td>0.9355 +/- 0.0195</td>\n",
       "      <td>0.9233 +/- 0.0217</td>\n",
       "      <td>[{'learning_rate': 0.041299973169667735, 'max_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name       Precision CV          Recall CV        F1 Score CV           Kappa CV Average Precision Score CV         ROC AUC CV                                             Params\n",
       "16       Lightgbm Classifier  0.8838 +/- 0.0192  0.8497 +/- 0.0266  0.8663 +/- 0.0213  0.7375 +/- 0.0422          0.9458 +/- 0.0189  0.9396 +/- 0.0182  [{'learning_rate': 0.016490254525097375, 'max_...\n",
       "40        XGBoost Classifier  0.8732 +/- 0.0229   0.849 +/- 0.0362  0.8607 +/- 0.0278  0.7245 +/- 0.0566          0.9379 +/- 0.0247   0.933 +/- 0.0271  [{'learning_rate': 0.0699516121742407, 'max_de...\n",
       "28  Random Forest Classifier      0.78 +/- 0.03      0.72 +/- 0.04      0.75 +/- 0.02      0.52 +/- 0.03              0.83 +/- 0.02      0.84 +/- 0.01  [{'max_depth': 3, 'min_samples_leaf': 5, 'n_es...\n",
       "21  Random Forest Classifier      0.83 +/- 0.02      0.81 +/- 0.02      0.82 +/- 0.02      0.65 +/- 0.03               0.9 +/- 0.02       0.9 +/- 0.01  [{'max_depth': 10, 'min_samples_leaf': 1, 'n_e...\n",
       "6        Lightgbm Classifier   0.8736 +/- 0.025  0.8184 +/- 0.0185   0.845 +/- 0.0199  0.7005 +/- 0.0431          0.9355 +/- 0.0195  0.9233 +/- 0.0217  [{'learning_rate': 0.041299973169667735, 'max_..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResults.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to .feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResults.to_feather('02-ModelsResults/dfModelResults.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
